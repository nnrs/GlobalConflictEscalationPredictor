{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "823d7bf2-0c4b-47b4-9957-06be37644a96",
   "metadata": {},
   "source": [
    "# PROJECT ASSIGNMENT #2\n",
    "### GROUP MEMBERS: Neil Chen, Will Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18910b-7a6a-4af6-a78c-2f001ddcf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_indicators = pd.read_csv('country_indicators.csv')\n",
    "df_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a028df-cef5-40ad-b90c-1aa04d93ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.read_csv('test_predictions.csv')\n",
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a4494-79c7-42c4-b8ed-38eb9be1bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_preds.merge(df_indicators, left_on='iso3', right_on='iso3', how='inner')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a62d09-3f09-4276-99f5-fd861a6d2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "column_defining_groups = 'fsi_category'\n",
    "\n",
    "chosen_metric = 'accuracy_score'\n",
    "\n",
    "metric_function = getattr(metrics, chosen_metric)\n",
    "\n",
    "chosen_metric_for_chosen_groups = list()\n",
    "chosen_metric_back_into_original_data = {'ffnn': pd.Series(index=df.index, dtype=np.float64), \n",
    "                                         'xgboost': pd.Series(index=df.index, dtype=np.float64), \n",
    "                                         'transformer': pd.Series(index=df.index, dtype=np.float64)}\n",
    "    \n",
    "for g, rows in df.groupby(column_defining_groups):\n",
    "    for model in ['ffnn', 'xgboost', 'transformer']:        \n",
    "        chosen_metric_value = metric_function(rows[f\"y_true_{model}\"], rows[f\"y_pred_{model}\"]) \n",
    "        \n",
    "        chosen_metric_back_into_original_data[model][rows.index] = chosen_metric_value\n",
    "        chosen_metric_for_chosen_groups.append((model, g, chosen_metric_value))\n",
    "\n",
    "cm_bigger_better = sns.light_palette(\"teal\", as_cmap=True)\n",
    "\n",
    "styler = ( pd.DataFrame(chosen_metric_for_chosen_groups, \n",
    "                        columns=('model', column_defining_groups, chosen_metric))\n",
    "            .sort_values(column_defining_groups).style\n",
    "            .background_gradient(cmap=cm_bigger_better)\n",
    "            .format(precision=5).hide(axis=\"index\"))\n",
    "styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170484d-3a9c-41ae-9d55-d0ff1c155008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth(df, \n",
    "                    locations='iso3',\n",
    "                    color='fsi_category',\n",
    "                    hover_name='iso3',\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740558da-a0d5-4f42-b63f-660ddfa5aa30",
   "metadata": {},
   "source": [
    "# ***HYPOTHESIS TEST*** $1$\n",
    "### (between all three models)\n",
    "\n",
    "\n",
    "We believe that the probability that all three models should accurately predict a true positive (correctly predicted escalation) or a true negative (correctly predicted no escalation) for the fsi category 'sustainable' is 0.5. This is because the model will either have to choose if a country has conflict escalation (positive) or no escalation (negative) and therefore, has a 0.5 chance that it is true and a 0.5 chance it is false. \n",
    "\n",
    "- Let t be 'correctly predicted escalation and no escalation' under **transformer** model for fsi category 'Sustainable'\n",
    "- Let f be 'correctly predicted escalation and no escalation' under **ffnn** model for fsi category 'Sustainable' \n",
    "- Let x be 'correctly predicted escalation and no escalation' under **xgboost** model for fsi category 'Sustainable'\n",
    "- Let c be 'correctly predicted escalation and no escalation' under **all three models** for fsi category 'Sustainable'\n",
    "\n",
    "$H_0: p_c = p_t + p_f + p_x = 0.5$\n",
    "\n",
    "$H_1$: Not $H_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4d583-1656-4122-821b-cfcb91271023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fsi_category.value_counts() #to count the number of countries with sustainable fsi_category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bee4c6-3284-4958-9319-f089c51ae2d0",
   "metadata": {},
   "source": [
    "## To Calculate ($p_t$): The Proportion of 'Correctly Predicted Escalation and No Escalation under transformer model for fsi category 'Sustainable' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed323c-17b0-4753-ba11-383ffc558192",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df_preds['transformer_classification_performance_outcome'] = 0.5\n",
    "\n",
    "tmpt = df_preds['transformer_classification_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmpt[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmpt[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "\n",
    "df_preds['transformer_classifcation_performance_outcome'] = tmpt\n",
    "df_preds[['y_true_transformer','y_pred_transformer','transformer_classification_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24759235-7133-4f14-af07-498fefffb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_TP_pos_pred_correct = (tmpt[TP_pos_pred_correct].groupby(df.fsi_category))\n",
    "pt_TP_pos_pred_correct.value_counts()/364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b388b92-a639-46f1-b03a-b2dd1aa293c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_TN_neg_pred_correct = (tmpt[TN_neg_pred_correct].groupby(df.fsi_category))\n",
    "pt_TN_neg_pred_correct.value_counts()/364"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c692f-e645-48f8-8a5d-6710d7d2a8f2",
   "metadata": {},
   "source": [
    "### $p_t = 0.002747 + 0.087912 = 0.090659$\n",
    "\n",
    "Let $p_t$ be the observed proportion of true positives under the ffnn model for sustainable fsi category plus the proportion of true negatives under the transformer model for sustainable fsi category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f65af0-43f8-473f-aa8b-b7208b8aef36",
   "metadata": {},
   "source": [
    "## To Calculate ($p_f$): The Proportion of 'Correctly Predicted Escalation and No Escalation under ffnn model for fsi category 'Sustainable' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3bd41-4212-4c5c-888d-bf52522ec777",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df_preds['ffnn_classification_performance_outcome'] = 0.5\n",
    "\n",
    "tmpf = df_preds['ffnn_classification_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_preds.y_true_ffnn & (df_preds.y_pred_proba_ffnn>threshold)\n",
    "tmpf[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_ffnn) & (df_preds.y_pred_proba_ffnn<=threshold)\n",
    "tmpf[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "\n",
    "df_preds['ffnn_classifcation_performance_outcome'] = tmpf\n",
    "df_preds[['y_true_ffnn','y_pred_ffnn','ffnn_classification_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef43262-25cd-4778-95da-fefa743de793",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_TP_pos_pred_correct = (tmpf[TP_pos_pred_correct].groupby(df.fsi_category))\n",
    "pf_TP_pos_pred_correct.value_counts()/364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a4e34-65a9-4538-bcc8-9a6751757984",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_TN_neg_pred_correct = (tmpf[TN_neg_pred_correct].groupby(df.fsi_category))\n",
    "pf_TN_neg_pred_correct.value_counts()/364"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95098c7c-d5e0-43ad-a005-f37e73689113",
   "metadata": {},
   "source": [
    "### $p_f = 0 + 0.090659 = 0.090659$\n",
    "\n",
    "Let $p_f$ be the observed proportion of true positives under the ffnn model for sustainable fsi category plus the proportion of true negatives under the ffnn model for sustainable fsi category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d3925a-0269-430b-991a-e4a9fea6898b",
   "metadata": {},
   "source": [
    "## To Calculate ($p_x$): The Proportion of 'Correctly Predicted Escalation and No Escalation under xgboost model for fsi category 'Sustainable' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ad36a-a618-4a2f-87a5-a38b993a79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df_preds['xgboost_classification_performance_outcome'] = 0.5\n",
    "\n",
    "tmpx = df_preds['xgboost_classification_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_preds.y_true_xgboost & (df_preds.y_pred_proba_xgboost>threshold)\n",
    "tmpx[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_xgboost) & (df_preds.y_pred_proba_xgboost<=threshold)\n",
    "tmpx[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "\n",
    "df_preds['xgboost_classifcation_performance_outcome'] = tmpx\n",
    "df_preds[['y_true_xgboost','y_pred_xgboost','xgboost_classification_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24682a82-d37f-434a-a91f-ae51f54166a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "px_TP_pos_pred_correct = (tmpx[TP_pos_pred_correct].groupby(df.fsi_category))\n",
    "px_TP_pos_pred_correct.value_counts()/364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f2370-de2c-4a43-8e6d-4ba33c40df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "px_TN_neg_pred_correct = (tmpx[TN_neg_pred_correct].groupby(df.fsi_category))\n",
    "px_TN_neg_pred_correct.value_counts()/364"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fed790-0a9a-4f36-8419-b698924fda63",
   "metadata": {},
   "source": [
    "### $p_x = 0 + 0.079670 = 0.079670$\n",
    "\n",
    "Let $p_x$ be the observed proportion of true positives under the xgboost model for sustainable fsi category plus the proportion of true negatives under the xgboost model for sustainable fsi category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7cdaae-e973-46df-a754-e773c397f14f",
   "metadata": {},
   "source": [
    "### Therefore, the observed test statistic would be the total observed proportion of true positives and true negatives for the sustainable fsi_category for all three models which is given by the equation:\n",
    "\n",
    "$p_c$ (observed) = $p_x$ (observed) + $p_f$ (observed) + $p_t$ (observed)\n",
    "\n",
    "$p_c$ (observed) = 0.079670 + 0.090659 + 0.090659\n",
    "\n",
    "$p_c$ (observed) = 0.260988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc003e-1b34-4e71-bb92-a8ee8b16f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_samples, n = 10000, 35 #n=35 since there are 35 countries with the sustainable fsi_category (as seen in ln6)\n",
    "p_hats = [] \n",
    "p = 0.5 # Null Hypothesis assumed proportion\n",
    "np.random.seed(100) \n",
    "for i in range(simulated_samples): \n",
    "    sample = np.random.choice(['True Positive and True Negative', 'False Positive and False Negative'], size=n, replace=True, p=[p, 1-p])\n",
    "    sample_prop = (sample == 'True Positive and True Negative').sum() / n\n",
    "    p_hats.append(sample_prop)\n",
    "\n",
    "observed_test_stat = 0.260988\n",
    "p = 0.5\n",
    "num_more_extreme = (abs(np.array(p_hats) - p) >= abs(observed_test_stat - p)).sum()\n",
    "p_value = num_more_extreme / simulated_samples\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35367a34-81cd-4575-99d6-9b9dbece67e0",
   "metadata": {},
   "source": [
    "Therefore, since we got a **p-value of 0.0051**, this shows that there is **very strong evidence against the null** which means that the probability that all three models (xgboost, ffnn and transformer) accurately predicted escalation or no escalation is **not equal to 0.5**. In reality, it can be seen that the probability of true positives and true negatives for the fsi category 'sustainable' is approximately 0.905 (the average of the accuracy score for all three models for the given category)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6133bc-5925-4c6e-b2ec-24ec5ffec4e8",
   "metadata": {},
   "source": [
    "# This concludes the Hypothesis Test $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a45762-4246-4f04-84a5-0f9f09f46cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visual aid for 'wbi_income_group' catagory for acuracy\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "column_defining_groups = 'wbi_income_group'\n",
    "chosen_metric = 'accuracy_score'\n",
    "\n",
    "metric_function = getattr(metrics, chosen_metric)\n",
    "\n",
    "chosen_metric_for_chosen_groups = list()\n",
    "chosen_metric_back_into_original_data = {'ffnn': pd.Series(index=df.index, dtype=np.float64), \n",
    "                                         'xgboost': pd.Series(index=df.index, dtype=np.float64), \n",
    "                                         'transformer': pd.Series(index=df.index, dtype=np.float64)}\n",
    "    \n",
    "for g, rows in df.groupby(column_defining_groups):\n",
    "    for model in ['ffnn', 'xgboost', 'transformer']:        \n",
    "        chosen_metric_value = metric_function(rows[f\"y_true_{model}\"], rows[f\"y_pred_{model}\"])\n",
    "\n",
    "        \n",
    "        chosen_metric_back_into_original_data[model][rows.index] = chosen_metric_value\n",
    "        chosen_metric_for_chosen_groups.append((model, g, chosen_metric_value))\n",
    "\n",
    "cm_bigger_better = sns.light_palette(\"pink\", as_cmap=True)\n",
    "styler = ( pd.DataFrame(chosen_metric_for_chosen_groups, \n",
    "                        columns=('model', column_defining_groups, chosen_metric))\n",
    "            .sort_values(column_defining_groups).style\n",
    "            .background_gradient(cmap=cm_bigger_better)\n",
    "            .format(precision=3).hide(axis=\"index\"))\n",
    "styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223e5c9-34dc-47d8-a707-a069f61b9f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map of wbi_income_group desplaying rows in colours\n",
    "import plotly.express as px\n",
    "fig = px.choropleth(df,\n",
    "                    locations='iso3',\n",
    "                    color='wbi_income_group',\n",
    "                    hover_name='iso3',\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a1367-045f-49c7-8305-96e99e81c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence intervals\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "df_visualization = pd.DataFrame(chosen_metric_for_chosen_groups, columns=('model', column_defining_groups, chosen_metric))\n",
    "\n",
    "def calculate_confidence_interval(data):\n",
    "    lower_bound = np.quantile(data, 0.025)\n",
    "    upper_bound = np.quantile(data, 0.975)\n",
    "    return lower_bound, upper_bound\n",
    "conf_intervals = df_visualization.groupby(column_defining_groups)[chosen_metric].apply(calculate_confidence_interval)\n",
    "conf_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9a83c-3ec5-4a9c-a8f8-4453f43d2df7",
   "metadata": {},
   "source": [
    "## Confidance interval of low income\n",
    " ***(0.2620689655172414, 0.5405172413793103)***\n",
    "\n",
    "Roughly: ***(0.26, 0.54)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14909fc9-b74f-4d9c-993f-07e5076cbe2c",
   "metadata": {},
   "source": [
    "# ***HYPOTHESIS TEST*** $2$\n",
    "The hypothesis assumes each model's (transformer, ffnn, and xgboost) error score of low income in countries is the same.\n",
    "\n",
    "***Introducing valuables:***\n",
    "\n",
    "- Let t be 'wrongly predicted escalation' under **transformer** model for fsi category 'Low income'\n",
    "- Let f be 'wrongly predicted escalation' under **ffnn** model for fsi category 'Low income' \n",
    "- Let x be 'wrongly predicted escalation' under **xgboost** model for fsi category 'Low income'\n",
    "- Let c be 'wrongly predicted escalation ' under **all three models** for fsi category 'Low income'\n",
    "\n",
    "# $H_0: p_c = p_t + p_f + p_x = 0.5$\n",
    "\n",
    "# Alternative Hypothesis\n",
    "the alternative hypothesis assumes that at least on the the models has a different score\n",
    "\n",
    "# $H_A: H_1: H_0 {is false}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde695f6-bcd7-41f1-b4b1-8c5e4d2eb0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code finds all the catagories of the df that have dtype 'object'\n",
    "list(df_indicators.select_dtypes(['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e619ca-71a8-4666-9ad8-4de602d851e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code counts the number of rows that have data for low income\n",
    "df_indicators.wbi_income_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98305bcc-5791-4c77-a4e0-195990fe18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Classification 'falsly predicted'(transformer model)\n",
    "\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "\n",
    "df_preds['transformer_classifcation_performance_outcome'] = 0.5\n",
    "\n",
    "tmpt = df_preds['transformer_classifcation_performance_outcome'].copy()\n",
    "\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmpt[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmpt[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['transformer_classifcation_performance_outcome'] = tmpt\n",
    "df_preds[['y_true_transformer','y_pred_transformer','transformer_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f47d4b-093d-420b-a5b4-9a1a453705ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrongly predicted positives (false positives)\n",
    "wrong_predictions_t = (tmpt[FP_pos_pred_wrong].groupby(df.wbi_income_group))\n",
    "wrong_predictions_t.value_counts()/364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba927d-0ab7-472e-bdfa-790dee7e3622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrongly predicted negatives (false negatives)\n",
    "wrong_predictions_t = (tmpt[FN_neg_pred_wrong].groupby(df.wbi_income_group))\n",
    "wrong_predictions_t.value_counts()/364"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633d4dbc-8f70-4e8e-9701-fb962b94d532",
   "metadata": {},
   "source": [
    " #### Wrongly predicting (false positive and false negative) ###\n",
    " '***low income***' in countries with ***transformer*** model w false positive= ***0.063187*** and false negative is= ***0.008242***\n",
    " \n",
    " $p_t= 0.063187+0.008242$ = ***0.145607*** (observed proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd813da-2a7a-431f-b174-5d8812cc017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Classification 'falsly predicted'(ffnn model)\n",
    "\n",
    "threshold = 0.5 \n",
    "df_preds['ffnn_classifcation_performance_outcome'] = 0.5\n",
    "\n",
    "tmp = df_preds['ffnn_classifcation_performance_outcome'].copy()\n",
    "\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_ffnn) & (df_preds.y_pred_proba_ffnn>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_ffnn & (df_preds.y_pred_proba_ffnn>threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['ffnn_classifcation_performance_outcome'] = tmp\n",
    "df_preds[['y_true_ffnn','y_pred_proba_ffnn','ffnn_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849a9d9-a7fa-42ec-8460-39ed88d6689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrongly predicted positives (false positives)\n",
    "wrong_predictions_f = (tmp[FP_pos_pred_wrong].groupby(df.wbi_income_group))\n",
    "wrong_predictions_f.value_counts()/364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4273464-3321-4461-b3f4-4a380d930a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrongly predicted negatives (false negatives)\n",
    "wrong_predictions_f = (tmp[FN_neg_pred_wrong].groupby(df.wbi_income_group))\n",
    "wrong_predictions_f.value_counts()/364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1718f1de-8b71-4be3-958f-400cbc84d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Classification 'falsly predicted'(xgboost model)\n",
    "\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "# using transformer for this example demonstration, as opposed to\n",
    "# df_preds.y_true_ffnn and df_preds.y_pred_proba_ffnn>threshold\n",
    "# df_preds.y_true_xgboost and df_preds.y_pred_proba_xgboost>threshold\n",
    "df_preds['xgboost_classifcation_performance_outcome'] = 0.5\n",
    "\n",
    "tmpr = df_preds['xgboost_classifcation_performance_outcome'].copy()\n",
    "\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_xgboost) & (df_preds.y_pred_proba_xgboost>threshold)\n",
    "tmpr[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_xgboost & (df_preds.y_pred_proba_xgboost<=threshold)\n",
    "tmpr[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['xgboost_classifcation_performance_outcome'] = tmp\n",
    "df_preds[['y_true_xgboost','y_pred_proba_xgboost','xgboost_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ca45b-4b16-47a3-b319-aa27b078bb1f",
   "metadata": {},
   "source": [
    " #### Wrongly predicting (false positive and false negative) ###\n",
    " '***low income***' in countries with ***ffnn*** model with false positive= ***0.118132*** and false negative is= ***0.038462***\n",
    " \n",
    " $p_f= 0.118132+0.038462$ = ***0.156594*** (observed proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff54636-0087-434f-a585-64ee5eb7ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Classification \"Correctness\" (xgboost model)\n",
    "\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "# using transformer for this example demonstration, as opposed to\n",
    "# df_preds.y_true_ffnn and df_preds.y_pred_proba_ffnn>threshold\n",
    "# df_preds.y_true_xgboost and df_preds.y_pred_proba_xgboost>threshold\n",
    "df_preds['xgboost_classifcation_performance_outcome'] = 0.5\n",
    "\n",
    "tmpr = df_preds['xgboost_classifcation_performance_outcome'].copy()\n",
    "\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_xgboost) & (df_preds.y_pred_proba_xgboost>threshold)\n",
    "tmpr[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_xgboost & (df_preds.y_pred_proba_xgboost<=threshold)\n",
    "tmpr[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['xgboost_classifcation_performance_outcome'] = tmp\n",
    "df_preds[['y_true_xgboost','y_pred_proba_xgboost','xgboost_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc542d0-f345-4844-a24e-7d0a6bfc689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrongly predicted positives (false positives)\n",
    "wrong_predictions_f = (tmpr[FP_pos_pred_wrong].groupby(df.wbi_income_group))\n",
    "wrong_predictions_f.value_counts()/364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0567fe4-67e9-47bd-aa90-dbea38f223e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrongly predicted negatives (false negatives)\n",
    "wrong_predictions_f = (tmpr[FN_neg_pred_wrong].groupby(df.wbi_income_group))\n",
    "wrong_predictions_f.value_counts()/364"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c5713-d583-4557-9a87-b28652749ca2",
   "metadata": {},
   "source": [
    " #### Wrongly predicting (false positive and false negative) ###\n",
    " '***low income***' in countries with ***ffnn*** model with false positive= ***0.107143*** and false negative is= ***0***\n",
    " \n",
    " $p_x = 0.107143+0$ = ***0.107143*** (observed proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bafeca-f87b-4736-99d9-fd45420db5d3",
   "metadata": {},
   "source": [
    "## Total  of observed test statistic:\n",
    "\n",
    "$p_c$ (observed) = $p_x$ (observed) + $p_f$ (observed) + $p_t$ (observed)\n",
    "\n",
    "$p_c$ (observed) = 0.145607 + 0.156594 + 0.107143\n",
    "\n",
    "$p_c$ (observed) = ***0.409344***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae1625-a24a-4dc2-8d40-67b9a199f52a",
   "metadata": {},
   "source": [
    "# Hypothesis test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f6da9-be7d-4b89-85d2-a33471df4939",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_samples, n = 10000, 35 #n=35 since there are 35 countries with the sustainable fsi_category (as seen in ln6)\n",
    "p_hats = [] \n",
    "p = 0.5 # Null Hypothesis assumed proportion\n",
    "np.random.seed(100) \n",
    "for i in range(simulated_samples): \n",
    "    sample = np.random.choice(['True Positive and True Negative', 'False Positive and False Negative'], size=n, replace=True, p=[p, 1-p])\n",
    "    sample_prop = (sample == 'False Positive and False Negative').sum() / n\n",
    "    p_hats.append(sample_prop)\n",
    "\n",
    "observed_test_stat = 0.409344\n",
    "p = 0.5\n",
    "num_more_extreme = (abs(np.array(p_hats) - p) >= abs(observed_test_stat - p)).sum()\n",
    "p_value = num_more_extreme / simulated_samples\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f79a75-d175-4b2e-86c4-75ad8bb01ea6",
   "metadata": {},
   "source": [
    "The hypothesis test concludes there is ***no evidance against*** the null hypothesis because the ***p-value*** is ***0.3139*** > 0.10. Concluding that there was no evidance to contridict the assumption that the models produce the same error results of 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc03d6a8-8cc3-421d-a618-ff452839c19f",
   "metadata": {},
   "source": [
    "# This Concludes Hypothesis Test $2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f8fdb-b4fe-45bd-a673-3b42b2a342b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"country_indicators.csv\")\n",
    "\n",
    "# Step 1: Drop redundant index column\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "# Step 2: Check missing value percentages\n",
    "missing_percent = df.isnull().mean()\n",
    "\n",
    "# Step 3: Drop columns with more than 50% missing values\n",
    "threshold = 0.5\n",
    "df = df.loc[:, missing_percent <= threshold]\n",
    "\n",
    "# Step 4: Separate and encode the target variable\n",
    "target = df[\"fsi_category\"]\n",
    "df = df.drop(columns=[\"fsi_category\"])\n",
    "\n",
    "# Step 5: Drop rows where target is missing\n",
    "mask = target.notnull()\n",
    "df = df[mask]\n",
    "target = target[mask]\n",
    "\n",
    "# Step 6: Fill remaining missing values with column means\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "# Step 7: Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "# Final features and labels\n",
    "X_final = df\n",
    "y_final = y_encoded\n",
    "\n",
    "# (Optional) Print dataset shape and label classes\n",
    "print(\"Final dataset shape:\", X_final.shape)\n",
    "print(\"Target classes:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d6c67-e4c0-49c9-8ac9-8e02ffa53ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"country_indicators.csv\")\n",
    "\n",
    "# Step 1: Drop redundant index column\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "# Step 2: Check missing value percentages\n",
    "missing_percent = df.isnull().mean()\n",
    "\n",
    "# Step 3: Drop columns with more than 50% missing values\n",
    "threshold = 0.5\n",
    "df = df.loc[:, missing_percent <= threshold]\n",
    "\n",
    "# Step 4: Separate and encode the target variable\n",
    "target = df[\"fsi_category\"]\n",
    "df = df.drop(columns=[\"fsi_category\"])\n",
    "\n",
    "# Step 5: Drop rows where target is missing\n",
    "mask = target.notnull()\n",
    "df = df[mask]\n",
    "target = target[mask]\n",
    "\n",
    "# Step 6: Fill remaining missing values with column means\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "# Step 7: Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "# Final features and labels\n",
    "X_final = df\n",
    "y_final = y_encoded\n",
    "\n",
    "# (Optional) Print dataset shape and label classes\n",
    "print(\"Final dataset shape:\", X_final.shape)\n",
    "print(\"Target classes:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3723c5-c161-425f-9b7d-7f84b63aeedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"country_indicators.csv\")\n",
    "\n",
    "# Step 1: Drop redundant index column\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "# Step 2: Check missing value percentages\n",
    "missing_percent = df.isnull().mean()\n",
    "\n",
    "# Step 3: Drop columns with more than 50% missing values\n",
    "threshold = 0.5\n",
    "df = df.loc[:, missing_percent <= threshold]\n",
    "\n",
    "# Step 4: Separate and encode the target variable\n",
    "target = df[\"fsi_category\"]\n",
    "df = df.drop(columns=[\"fsi_category\"])\n",
    "\n",
    "# Step 5: Drop rows where target is missing\n",
    "mask = target.notnull()\n",
    "df = df[mask]\n",
    "target = target[mask]\n",
    "\n",
    "# Step 6: Fill remaining missing values with column means\n",
    "df = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "# Step 7: Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "# Final features and labels\n",
    "X_final = df\n",
    "y_final = y_encoded\n",
    "\n",
    "# (Optional) Print dataset shape and label classes\n",
    "print(\"Final dataset shape:\", X_final.shape)\n",
    "print(\"Target classes:\", label_encoder.classes_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
